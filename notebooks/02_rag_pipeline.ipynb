{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Workshop - Part 2: Building the RAG Pipeline\n",
    "\n",
    "In this notebook, we'll build a complete RAG system:\n",
    "1. **Load & Index**: Process documents into a vector store\n",
    "2. **Retrieve**: Find relevant context for queries\n",
    "3. **Generate**: Use LLM with retrieved context\n",
    "4. **Test**: See what works and what doesn't"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Environment loaded!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Verify API key\n",
    "assert os.getenv(\"GOOGLE_API_KEY\"), \"Please set GOOGLE_API_KEY in .env file\"\n",
    "print(\"‚úÖ Environment loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Load Documents\n",
    "\n",
    "We'll use LangChain's document loaders to read our course syllabi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 8 documents\n",
      "  - CS101.md: 3066 chars\n",
      "  - CS201.md: 3516 chars\n",
      "  - CS301.md: 4197 chars\n",
      "  - CS401.md: 4455 chars\n",
      "  - CS501.md: 4324 chars\n",
      "  - MATH101.md: 3569 chars\n",
      "  - MATH201.md: 3968 chars\n",
      "  - STAT101.md: 4084 chars\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "\n",
    "# Load all markdown files from syllabi folder\n",
    "loader = DirectoryLoader(\n",
    "    \"../data/syllabi\",\n",
    "    glob=\"**/*.md\",\n",
    "    loader_cls=TextLoader,\n",
    "    loader_kwargs={\"encoding\": \"utf-8\"}\n",
    ")\n",
    "\n",
    "documents = loader.load()\n",
    "\n",
    "print(f\"Loaded {len(documents)} documents\")\n",
    "for doc in documents:\n",
    "    print(f\"  - {Path(doc.metadata['source']).name}: {len(doc.page_content)} chars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chunk Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 90 chunks from 8 documents\n",
      "\n",
      "Sample chunk:\n",
      "----------------------------------------\n",
      "### Module 3: Functions (Weeks 5-6)\n",
      "- Defining and calling functions\n",
      "- Parameters and return values\n",
      "- Scope and lifetime of variables\n",
      "- Built-in functions and modules\n",
      "\n",
      "### Module 4: Data Structures (Weeks 7-9)\n",
      "- Lists and list operations\n",
      "- Strings and string manipulation\n",
      "- Dictionaries and sets\n",
      "- Ne\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Create text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    "    separators=[\"\\n## \", \"\\n### \", \"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
    ")\n",
    "\n",
    "# Split documents\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"Created {len(chunks)} chunks from {len(documents)} documents\")\n",
    "print(f\"\\nSample chunk:\")\n",
    "print(\"-\" * 40)\n",
    "print(chunks[5].page_content[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model...\n",
      "Creating vector store...\n",
      "‚úÖ Vector store created with 90 chunks!\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# Use local embedding model (no API cost!)\n",
    "print(\"Loading embedding model...\")\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"all-MiniLM-L6-v2\",\n",
    "    model_kwargs={\"device\": \"cpu\"}\n",
    ")\n",
    "\n",
    "# Create vector store\n",
    "print(\"Creating vector store...\")\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embeddings,\n",
    "    collection_name=\"course_advisor\"\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Vector store created with {len(chunks)} chunks!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What topics are covered in machine learning?\n",
      "Retrieved 4 chunks:\n",
      "\n",
      "[1] From CS301:\n",
      "## Course Description\n",
      "\n",
      "This course provides a comprehensive introduction to machine learning, covering both theoretical foundations and practical applications. Students will learn the fundamental algo...\n",
      "\n",
      "[2] From CS301:\n",
      "## Topics Covered\n",
      "\n",
      "### Module 1: Foundations (Weeks 1-2)\n",
      "- What is machine learning?\n",
      "- Types of ML: supervised, unsupervised, reinforcement\n",
      "- The ML pipeline: data collection, preprocessing, modeling,...\n",
      "\n",
      "[3] From CS301:\n",
      "Upon successful completion of this course, students will be able to:\n",
      "- Understand the mathematical foundations of machine learning algorithms\n",
      "- Implement and apply supervised learning algorithms (regr...\n",
      "\n",
      "[4] From CS301:\n",
      "The course bridges the gap between mathematical theory and real-world implementation. Students will gain hands-on experience with popular machine learning libraries (scikit-learn, pandas, numpy) while...\n"
     ]
    }
   ],
   "source": [
    "# Create retriever\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 4}  # Return top 4 chunks\n",
    ")\n",
    "\n",
    "# Test retrieval\n",
    "query = \"What topics are covered in machine learning?\"\n",
    "docs = retriever.invoke(query)\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"Retrieved {len(docs)} chunks:\")\n",
    "for i, doc in enumerate(docs):\n",
    "    source = Path(doc.metadata['source']).stem\n",
    "    print(f\"\\n[{i+1}] From {source}:\")\n",
    "    print(doc.page_content[:200] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Set Up LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LLM initialized!\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# Initialize Gemini\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    temperature=0,\n",
    "    max_output_tokens=1024\n",
    ")\n",
    "\n",
    "print(\"‚úÖ LLM initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Build RAG Chain\n",
    "\n",
    "Now we combine retrieval + LLM generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ RAG chain built!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# RAG prompt template\n",
    "template = \"\"\"You are a helpful course advisor for Fictional University.\n",
    "Answer the question based ONLY on the following context. \n",
    "If the context doesn't contain enough information, say \"I don't have enough information to answer that.\"\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# Helper to format documents\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n---\\n\\n\".join(\n",
    "        f\"[Source: {Path(doc.metadata['source']).stem}]\\n{doc.page_content}\"\n",
    "        for doc in docs\n",
    "    )\n",
    "\n",
    "# Build the RAG chain\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": retriever | format_docs,\n",
    "        \"question\": RunnablePassthrough()\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"‚úÖ RAG chain built!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Understanding the LCEL Chain Syntax\n\nThe `|` operator is **LangChain Expression Language (LCEL)** - it pipes data through each step like Unix pipes.\n\n```\n\"What is CS301?\" ‚îÄ‚îÄ‚ñ∫ { parallel execution } ‚îÄ‚îÄ‚ñ∫ prompt ‚îÄ‚îÄ‚ñ∫ llm ‚îÄ‚îÄ‚ñ∫ StrOutputParser ‚îÄ‚îÄ‚ñ∫ \"Answer...\"\n```\n\n**Breaking it down:**\n\n| Component | What it does |\n|-----------|--------------|\n| `{\"context\": ..., \"question\": ...}` | Creates a dict with two parallel branches |\n| `retriever \\| format_docs` | Finds relevant docs ‚Üí formats them as a string |\n| `RunnablePassthrough()` | Passes input unchanged (identity function) |\n| `prompt` | Fills template placeholders with the dict values |\n| `llm` | Sends prompt to Gemini, returns AI message |\n| `StrOutputParser()` | Extracts just the text from the response |\n\n**Data flow example:**\n```python\n# Input: \"What is CS301?\"\n\n# After first stage (parallel dict):\n{\"context\": \"[CS301] Machine learning course...\", \"question\": \"What is CS301?\"}\n\n# After prompt: formatted prompt string with context + question filled in\n# After llm: AIMessage object with response\n# After StrOutputParser: \"CS301 is a machine learning course...\"\n```",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test the RAG System\n",
    "\n",
    "Let's test with various types of questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(question):\n",
    "    \"\"\"Ask a question and show the answer.\"\"\"\n",
    "    print(f\"Question: {question}\")\n",
    "    print(\"-\" * 50)\n",
    "    answer = rag_chain.invoke(question)\n",
    "    print(f\"Answer: {answer}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What topics are covered in the Machine Learning course?\n",
      "--------------------------------------------------\n",
      "Answer: The Machine Learning course covers the following topics:\n",
      "\n",
      "Module 1: Foundations (Weeks 1-2)\n",
      "- What is machine learning?\n",
      "- Types of ML: supervised, unsupervised, reinforcement\n",
      "- The ML pipeline: data collection, preprocessing, modeling, evaluation\n",
      "- Python ML ecosystem (numpy, pandas, scikit-learn)\n",
      "\n",
      "Module 2: Supervised Learning - Regression (Weeks 3-4)\n",
      "- Linear regression\n",
      "- Polynomial regression\n",
      "- Regularization (Ridge, Lasso)\n",
      "- Gradient descent optimization\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Simple factual question\n",
    "ask(\"What topics are covered in the Machine Learning course?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who teaches Linear Algebra?\n",
      "--------------------------------------------------\n",
      "Answer: I don't have enough information to answer that.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test 2: Who teaches a course?\n",
    "ask(\"Who teaches Linear Algebra?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What are the prerequisites for the Deep Learning course?\n",
      "--------------------------------------------------\n",
      "Answer: The prerequisite for CS401 (Deep Learning) is CS301 (Introduction to Machine Learning).\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test 3: Prerequisites question\n",
    "ask(\"What are the prerequisites for the Deep Learning course?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What's the difference between CS301 and CS401?\n",
      "--------------------------------------------------\n",
      "Answer: I don't have enough information to answer that.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test 4: Comparison question\n",
    "ask(\"What's the difference between CS301 and CS401?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Challenge: Complex Relationship Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Can I take CS401 (Deep Learning) if I've only completed CS101?\n",
      "--------------------------------------------------\n",
      "Answer: No, you cannot take CS401 (Deep Learning) if you've only completed CS101. CS401 requires CS301 (Introduction to Machine Learning) as a prerequisite.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test 5: This is harder!\n",
    "ask(\"Can I take CS401 (Deep Learning) if I've only completed CS101?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: I want to become an NLP specialist. What courses should I take and in what order?\n",
      "--------------------------------------------------\n",
      "Answer: I don't have enough information to answer that.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test 6: Learning path question\n",
    "ask(\"I want to become an NLP specialist. What courses should I take and in what order?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis: What Works and What Doesn't?\n",
    "\n",
    "| Query Type | Works Well? | Why |\n",
    "|------------|-------------|-----|\n",
    "| Simple facts | ‚úÖ Yes | Direct retrieval |\n",
    "| Who teaches X? | ‚úÖ Yes | Info in single chunk |\n",
    "| Prerequisites for X? | ‚úÖ Mostly | Usually in same doc |\n",
    "| Can I take X given Y? | ‚ö†Ô∏è Sometimes | Needs reasoning across chunks |\n",
    "| Full learning path | ‚ùå Often fails | Needs multi-hop reasoning |\n",
    "\n",
    "**The limitation**: Simple RAG retrieves relevant chunks, but can't reason across them or traverse relationship chains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Adding Source Attribution\n",
    "\n",
    "Let's enhance our system to show which sources were used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_with_sources(question):\n",
    "    \"\"\"Ask a question and show answer with sources.\"\"\"\n",
    "    # Get relevant documents\n",
    "    docs = retriever.invoke(question)\n",
    "    \n",
    "    # Format context\n",
    "    context = format_docs(docs)\n",
    "    \n",
    "    # Generate answer\n",
    "    messages = prompt.format_messages(context=context, question=question)\n",
    "    response = llm.invoke(messages)\n",
    "    \n",
    "    print(f\"Question: {question}\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"\\nAnswer: {response.content}\")\n",
    "    \n",
    "    print(f\"\\nüìö Sources used:\")\n",
    "    sources = set(Path(doc.metadata['source']).stem for doc in docs)\n",
    "    for source in sources:\n",
    "        print(f\"  - {source}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What programming languages are used in the courses?\n",
      "==================================================\n",
      "\n",
      "Answer: CS101 uses Python. I don't have information about the programming languages used in CS201.\n",
      "\n",
      "üìö Sources used:\n",
      "  - CS201\n",
      "  - CS101\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ask_with_sources(\"What programming languages are used in the courses?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Experimenting with Parameters\n",
    "\n",
    "Let's see how changing parameters affects results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With k=2 (fewer chunks):\n",
      "  - CS301\n",
      "  - CS301\n",
      "\n",
      "With k=8 (more chunks):\n",
      "  - CS301\n",
      "  - CS301\n",
      "  - CS301\n",
      "  - CS301\n",
      "  - CS501\n",
      "  - MATH201\n",
      "  - CS301\n",
      "  - CS401\n"
     ]
    }
   ],
   "source": [
    "# More chunks = more context\n",
    "retriever_more = vectorstore.as_retriever(search_kwargs={\"k\": 8})\n",
    "\n",
    "# Fewer chunks = more focused\n",
    "retriever_fewer = vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
    "\n",
    "question = \"What math is needed for machine learning?\"\n",
    "\n",
    "print(\"With k=2 (fewer chunks):\")\n",
    "docs = retriever_fewer.invoke(question)\n",
    "for doc in docs:\n",
    "    print(f\"  - {Path(doc.metadata['source']).stem}\")\n",
    "\n",
    "print(\"\\nWith k=8 (more chunks):\")\n",
    "docs = retriever_more.invoke(question)\n",
    "for doc in docs:\n",
    "    print(f\"  - {Path(doc.metadata['source']).stem}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this notebook, we built a complete RAG pipeline:\n",
    "\n",
    "1. **Document Loading**: Used LangChain loaders to read markdown files\n",
    "2. **Chunking**: Split documents into 500-char chunks with overlap\n",
    "3. **Vector Store**: Indexed chunks in ChromaDB with sentence-transformers\n",
    "4. **Retrieval**: Found relevant chunks using semantic search\n",
    "5. **Generation**: Combined context with Gemini to generate answers\n",
    "6. **Source Attribution**: Showed which documents were used\n",
    "\n",
    "### Limitations Discovered\n",
    "- Works great for simple factual questions\n",
    "- Struggles with multi-hop reasoning (prerequisite chains)\n",
    "- Can't plan learning paths effectively\n",
    "\n",
    "**Next**: In notebook 03, we'll build an Agentic RAG system that can reason through complex queries!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}